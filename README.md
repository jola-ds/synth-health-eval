# Synthetic Data Augmentation for Geriatric Health in Nigeria

![Python](https://img.shields.io/badge/python-3.8%2B-blue) ![License](https://img.shields.io/badge/license-MIT-green)

## Research Question

Can synthetic data generated from a tiny clinical seed dataset support useful
and safe modelling?

**Objectives:** To evaluate the utility, fidelity, and privacy of synthetic
data generated from a small (N=134) real-world clinical dataset of geriatric
patients in Ibadan, Nigeria.

## Result

This research demonstrates that for small, specialized clinical
datasets, statistical generative models (like Gaussian Copula) are far more
effective than complex deep learning approaches. We found that synthetic data
serves as a powerful 'digital stabilizer'â€”when used to augment real records, it
preserves the predictive power of the original data while ensuring patient
privacy. This proves that synthetic data can effectively amplify
under-represented African healthcare datasets, allowing us to build robust AI
tools even in low-resource environments.

## Executive Summary

**Synthetic Data Augmentation** offers a transformative solution to the dual
challenges of **Data Privacy** and **Data Scarcity** in healthcare. This project
applies globally validated synthetic data frameworks to a specific, high-risk
context: **Geriatric Hypertension Prediction in Nigeria**.

## Motivation

In Nigeria healthcare datasets are often fragmented, paper-based, and too small
for modern AI. This project addresses the **"Cold Start" problem** for African
AI, demonstrating how we can ethically augment a small dataset ($N=134$) into a
resource for hypertension prediction without compromising patient privacy
or sovereignty.

> [**Read the Literature Review & Background**](0_domain_study/README.md)

---

## Analysis Approach

Our methodology followed a strict five-phase pipeline:

1. **Imputation Shootout:** We compared MICE, KNN, and MissForest to handle
missing values. **MICE** won with the lowest distribution shift.

2. **Generator Screening:** We trained and compared Gaussian Copula
(Statistical) and CTGAN (Deep Learning).

3. **Privacy Check:** We performed a Distance to Closest Record (DCR)
privacy audit

<!-- markdownlint-disable MD029 -->
4. **Utility Evaluation:** We ran a **Repeated Stratified K-Fold Cross-Validation
(5x5)** to evaluate models under four scenarios:

* *Scenario A (Baseline):* Train Real, Test Real.
* *Scenario B (Fidelity):* Train Synthetic, Test Real.
* *Scenario C (Scale):* Train Large Synthetic, Test Real.
* *Scenario D (Augment):* Train Real + Synthetic, Test Real.

5. **Fidelity Audit:** We used KS Tests, Correlation Matrices, and Adversarial
AUC to quantify the statistical quality of the synthetic data.
<!-- markdownlint-enable MD029 -->

![Top Predictors](/2_data_analysis/images/shap_summary_bar.png)

> [*Read the full Methodology*](2_data_analysis/methodology.md).

---

## Research Conclusions

**1. Augmentation Maintained Utility:**
Augmenting the small real dataset with **50% synthetic data** generated by a
**Gaussian Copula** model maintained the baseline F1-Score (0.826)
while potentially increasing model robustness. This was the optimal strategy.

**2. Statistical Models Beat Deep Learning:**
For this small sample size, the statistical **Gaussian Copula** generator
significantly outperformed the deep learning-based **CTGAN**.

* **Copula:** Captured ~88% of the signal (Fidelity F1: 0.727).
* **CTGAN:** Failed to converge, performing near random chance (Fidelity F1:
0.470).

**3. Privacy is Preserved:**
Both generators successfully passed the Distance to Closest Record (DCR)
privacy audit, ensuring no real patient records were memorized or leaked.

**4. Fidelity is Maintained:**
The copula-generated synthetic data preserved 92% of univariate distributions
and 89% of correlation structures, while remaining realistically
indistinguishable from real patient records (Adversarial AUC 0.64).

**5. Limits of Synthetic Scaling:**
Contrary to the intuition that "more data is better," we found that:

* Aggressive augmentation (>100% synthetic data) degraded performance by
diluting the true signal.
* Training solely on synthetic data (1:1) yielded lower predictive power than
the baseline.
* Generating a larger dataset (e.g., N=1000) from this small seed did not
improve performance.

<!-- markdownlint-disable MD013 -->
| Scenario | Description | F1-Score | Accuracy | AUC | Verdict |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **A. Baseline** | Real Data Only | 0.826 | 0.842 | 0.898 | Gold Standard |
| **B. Fidelity** | Synthetic Only | 0.727 | 0.744 | 0.812 | Good Approximation |
| **D. Augment** | Real + 50% Syn | **0.825** | **0.841** | **0.891** |**Matches Baseline**|
<!-- markdownlint-enable MD013 -->

> [*Read the full Analysis Report*](2_data_analysis/analysis_report.md).

---

## Limitations

* **Sample Size:** The original dataset is very small (N=134). While this makes
the augmentation result impressive, it limits the complexity of models we can
train.
* **Linearity:** The Gaussian Copula assumes somewhat linear relationships
(Gaussian correlations). It may miss complex, non-linear interactions that a
converged GAN could capture if more data were available.
* **Generalizability:** Findings are specific to this geriatric hypertension
dataset and may not transfer 1:1 to other domains (e.g., imaging).

> **Project Context:** Due to significant challenges, the project timeline
was compressed, delivering a two-month research scope in under four weeks.

---

## Future Research

1. **Bayesian Networks:** Manually defining causal edges (e.g., `Age ->
Hypertension`) could improve fidelity beyond the Copula by enforcing known
biological constraints.
2. **Differential Privacy:** Implementing formal epsilon-differential privacy
during training to provide mathematical privacy guarantees.
3. **External Validation:** Testing the "Augmented" model on a completely
external dataset from a different clinic to prove true generalization.

---

## ðŸ“‚ Repository Structure

<!-- markdownlint-disable MD013 -->
| Directory / File | Description |
| :--- | :--- |
| **[`1_datasets/`](1_datasets/)** | Raw and imputed data, Data Overview & Preprocessing report. |
| **[`2_data_analysis/`](2_data_analysis/)** | The core methodology + Findings. |
| â”œâ”€â”€ [`analysis_report.md`](2_data_analysis/analysis_report.md) | Detailed analysis report. |
| â”œâ”€â”€ [`methodology.md`](2_data_analysis/methodology.md) | Full technical explanation of the pipeline. |
| â””â”€â”€ [`results/`](2_data_analysis/results/) | Raw CSVs from the evaluation loop. |
| **[`3_notebooks/`](3_notebooks/)** | Interactive Jupyter notebooks for exploration. |
| â”œâ”€â”€ [`01_preprocessing.ipynb`](3_notebooks/01_preprocessing.ipynb) | Data preprocessing pipeline. |
| **[`4_src/`](4_src/)** | Python source code modules (`generation.py`, `evaluation.py`, etc.). |
<!-- markdownlint-enable MD013 -->

---

## Getting Started

### Prerequisites

* Python 3.8+
* pip

### Installation

1. Clone the repository:

    ```bash
    git clone https://github.com/yourusername/synth-health-eval.git
    cd synth-health-eval
    ```

2. Install dependencies:

    ```bash
    pip install -r requirements.txt
    ```

---

## Usage Guide (Reproduce the Analysis)

To replicate these findings, run the pipeline in the following order:

1. **Preprocessing:** Clean and encode the data.
    * *Script:* `3_notebooks/01_preprocessing.ipynb` (Interactive)
    * *Output:* `1_datasets/encoded_data.csv`

2. **Imputation:** Fill missing values using the Hybrid Strategy
(MICE + Stratified Median).
    * *Command:* `python 4_src/imputation.py`
    * *Output:* `1_datasets/imputed_data.csv`

3. **Generation:** Train models (Copula/CTGAN) and generate synthetic cohorts.
    * *Command:* `python 4_src/generation.py`
    * *Output:* `1_datasets/synthetic_sample/`

4. **Evaluation:** Run the TRTR-TSTR utility benchmark.
    * *Command:* `python 4_src/evaluation.py`
    * *Output:* `2_data_analysis/results/master_loop_results.csv`

5. **Fidelity:** Run the Fidelity Audit.
    * *Command:* `python 4_src/fidelity.py`
    * *Output:* `2_data_analysis/results/fidelity_results.csv`

---

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE)
file for details.
